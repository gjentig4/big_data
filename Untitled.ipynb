{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80770f36-9a9f-4c67-800d-a6fd05576579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import nltk\n",
    "import re\n",
    "#Try also with encoding='ISO-8859-1' \n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding='latin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7b5d625-14d9-42f4-8596-76c9200da72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['pola', 'id', 'date', 'query', 'user', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e802e0e6-ed88-4594-97d1-071199238bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URLs from tweets\n",
    "df['clean_tweet'] = df['text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "# Remove user mentions (@)\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(r'@[A-Za-z0-9_]+', '', x))\n",
    "\n",
    "# Remove numbers and special characters\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub('[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "# Convert to lowercase\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: x.lower())\n",
    "\n",
    "# Tokenize tweets\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eec2ad67-66e4-415a-878f-968d3e9af144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'upset', 'that', 'he', 'cant', 'update', 'his', 'facebook', 'by', 'texting', 'it', 'and', 'might', 'cry', 'as', 'a', 'result', 'school', 'today', 'also', 'blah']\n"
     ]
    }
   ],
   "source": [
    "print(df['clean_tweet'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e05b1fb-80a3-40f9-8489-18cd7e433437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9ede923-65d0-499a-b7f2-c8bcb68e18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words and lemmatize tokens\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda tweet: [lemmatizer.lemmatize(word) for word in tweet if word not in stop_words])\n",
    "\n",
    "# Join tokens back into a single string\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda tweet: ' '.join(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "347b4963-8439-4a2b-93e2-54fd4c177710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    upset cant update facebook texting might cry r...\n",
      "1      dived many time ball managed save rest go bound\n",
      "2                      whole body feel itchy like fire\n",
      "3                             behaving im mad cant see\n",
      "4                                           whole crew\n",
      "Name: clean_tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['clean_tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47e90d4b-8bca-4fa1-8e34-debcd25fad1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   pola         1599999 non-null  int64 \n",
      " 1   id           1599999 non-null  int64 \n",
      " 2   date         1599999 non-null  object\n",
      " 3   query        1599999 non-null  object\n",
      " 4   user         1599999 non-null  object\n",
      " 5   text         1599999 non-null  object\n",
      " 6   clean_tweet  1599999 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 85.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5264931-4f2a-4481-bec8-e9786faa3d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pola', 'id', 'date', 'query', 'user', 'text', 'clean_tweet'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06d7e603-78e5-4c67-b389-6958b998abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(['id', 'date', 'query', 'user', 'text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfcc90be-f3ed-4c16-948c-d9f6692ee7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save cleaned dataset to a new CSV file\n",
    "df.to_csv('preprocessed_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ee17e-9052-497f-894a-6d53e02f23de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
